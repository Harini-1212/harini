# -*- coding: utf-8 -*-
"""Copy of Copy of Copy of harini.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JmRpiBq-PqAC-j5mwzDbD9KauBX0b33W
"""

import pandas as pd
import numpy as numpy
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

df1=pd.read_csv("/content/customer_data.csv")
df1.head()

df2=pd.read_csv("/content/payment_data.csv")
df2.head()

df1.shape

df2.shape

df1.isnull().sum()

df=pd.DataFrame(df1)

df_cleaned=df.dropna(axis=0,inplace=True)

df_cleaned

df.isnull().sum()

df2.isnull().sum()

data=pd.DataFrame(df2)

data_cleaned=data.dropna(axis=0,inplace=True)

data_cleaned

data.isnull().sum()

df.describe()

merged=pd.merge(df1,df2,on='id')

merged

merged.value_counts

sns.boxplot(data=merged,x="fea_1",y="fea_2")
plt.title('Box Plot')
plt.show()

sns.boxplot(data=merged,x='fea_1',y='OVD_t2')
plt.title('Box Plot')
plt.show()

plt.figure(figsize=(10,5))
sns.histplot(merged['fea_1'],bins=80)
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

features = ['OVD_t1', 'OVD_t2', 'OVD_t3', 'OVD_sum', 'pay_normal', 'prod_limit', 'fea_1', 'fea_3', 'fea_5', 'fea_6', 'fea_7', 'fea_9']
target = 'label'

X = merged[features]
y = merged[target]

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

data = df2.merge(df1, on='id', how='inner')

data['update_date'] = (pd.to_datetime(data['update_date']) - pd.Timestamp("2000-01-01")).dt.days
data['report_date'] = (pd.to_datetime(data['report_date']) - pd.Timestamp("2000-01-01")).dt.days

features = ['OVD_t1', 'OVD_t2', 'OVD_t3', 'OVD_sum', 'pay_normal','fea_1', 'fea_3', 'fea_5', 'fea_6', 'fea_7', 'fea_9']
target = 'label'

X = data[features]
y = data[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
model = LogisticRegression()

model.fit(X_train_scaled, y_train)


predictions = model.predict(X_test_scaled)

accuracy = accuracy_score(y_test, predictions)
conf_matrix = confusion_matrix(y_test, predictions)
classification_rep = classification_report(y_test, predictions)

print("Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", classification_rep)

model=RandomForestClassifier(n_estimators=100, random_state=42)

model.fit(X_train,y_train)

predictions=model.predict(X_test)
predictions

accuracy = accuracy_score(y_test, predictions)
conf_matrix = confusion_matrix(y_test, predictions)
classification_rep = classification_report(y_test, predictions)

print("Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", classification_rep)

df2 = pd.read_csv('/content/payment_data.csv')
df1 = pd.read_csv('/content/customer_data.csv')
data = pd.merge(df2, df1, on='id')

features = ['OVD_t1', 'OVD_t2', 'OVD_t3', 'OVD_sum', 'pay_normal','fea_1', 'fea_3', 'fea_5', 'fea_6', 'fea_7', 'fea_9']
target = 'label'

X = merged[features]
y = merged[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)

svm_classifier.fit(X_train_scaled, y_train)

y_pred = svm_classifier.predict(X_test_scaled)
y_pred

accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

print(f'Accuracy: {accuracy:.2f}')
print(f'Classification Report:\n{classification_rep}')

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report

df2 = pd.read_csv('/content/payment_data.csv')
df1 = pd.read_csv('/content/customer_data.csv')
data = pd.merge(df1, df2, on='id')

features = ['OVD_t1', 'OVD_t2', 'OVD_t3', 'OVD_sum', 'pay_normal','fea_1', 'fea_3', 'fea_5', 'fea_6', 'fea_7', 'fea_9']
target = 'label'

X = merged[features]
y = merged['label']

random_forest = RandomForestClassifier(n_estimators=100, random_state=42)
gradient_boosting = GradientBoostingClassifier(n_estimators=100, random_state=42)

random_forest.fit(X_train_scaled, y_train)
gradient_boosting.fit(X_train_scaled, y_train)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(X_train, y_train)

y_pred_rf = rf_classifier.predict(X_test)

accuracy = accuracy_score(y_test, y_pred_rf)
print(f"Accuracy: {accuracy}")

features = ['OVD_t1', 'OVD_t2', 'OVD_t3', 'OVD_sum', 'pay_normal','fea_1', 'fea_3', 'fea_5', 'fea_6', 'fea_7', 'fea_9']
target = 'label'

X = merged[features]
y = merged['label']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

from sklearn.cluster import KMeans

inertia = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)

plt.figure(figsize=(8, 6))
plt.plot(range(1, 11), inertia, marker='o')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.show()

X = data.drop('label', axis=1)
y = data['label']

num_clusters = 3


kmeans = KMeans(n_clusters=num_clusters, random_state=42)
kmeans.fit(X_scaled)

data['cluster'] = kmeans.labels_

plt.figure(figsize=(10, 6))
sns.scatterplot(x='OVD_sum', y='prod_limit', hue='cluster', data=data, palette='Set1')
plt.title('K-Means Clustering')
plt.xlabel('Total Overdue Days')
plt.ylabel('Product Limit')
plt.show()

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report

features = ['OVD_t1', 'OVD_t2', 'OVD_t3', 'pay_normal','fea_1', 'fea_3', 'fea_5', 'fea_6', 'fea_7', 'fea_9']
target = 'label'

df2 = pd.read_csv('/content/payment_data.csv')
df1 = pd.read_csv('/content/customer_data.csv')
data = pd.merge(df2, df1, on='id')

data = data.drop(['id', 'update_date', 'report_date'], axis=1)
X = data.drop('label', axis=1)
y = data['label']

data = pd.merge(df2, df1, on='id')

data = data.drop(['id', 'update_date', 'report_date'], axis=1)

data.fillna(0, inplace=True)  # Fill missing values with 0 or use other strategies


X = data.drop('label', axis=1)
y = data['label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

naive_bayes = GaussianNB()

naive_bayes.fit(X_train_scaled, y_train)

y_pred = naive_bayes.predict(X_test_scaled)

accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy:.2f}")
print("Classification Report:\n", classification_rep)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

df2 = pd.read_csv('/content/payment_data.csv')
df1 = pd.read_csv('/content/customer_data.csv')
data = pd.merge(df2, df1, on='id')

data = data.drop(['id', 'update_date', 'report_date'], axis=1)

data.fillna(0, inplace=True)  # Replace missing values with 0

X = data.drop('label', axis=1)
y = data['label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)


rf_classifier.fit(X_train_scaled, y_train)


y_pred = rf_classifier.predict(X_test_scaled)

accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy:.2f}")
print("Classification Report:\n", classification_rep)

